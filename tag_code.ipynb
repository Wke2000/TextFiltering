{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 1**"
      ],
      "metadata": {
        "id": "VxIzutU6McPD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYQ-fhgGdtji",
        "outputId": "a82bb573-d6f1-4053-aa10-1a3fdbbe7d18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas openpyxl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gupUSuvrNiwx",
        "outputId": "d3b17a77-c6b2-4645-da6a-98411825d2e9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import CODE\n",
        "import pandas as pd\n",
        "import openpyxl"
      ],
      "metadata": {
        "id": "9guFEVtS1PUs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_excel('/content/tag respiration 230917.xlsx')"
      ],
      "metadata": {
        "id": "cH6QT85H2IIG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This is for finding the first level classification\n",
        "CODE.result.to_excel('1st_classification.xlsx')"
      ],
      "metadata": {
        "id": "C019mCO21dHc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 2**"
      ],
      "metadata": {
        "id": "iyInBtX0MqD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folder_name = \"folder\"\n",
        "\n",
        "# 如果文件夹不存在，则创建它\n",
        "os.makedirs(folder_name, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "rzmoPrBbO2yS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This is for extracting groups\n",
        "\n",
        "\n",
        "original_workbook = openpyxl.load_workbook('/content/1st_classification.xlsx')\n",
        "original_sheet = original_workbook.active\n",
        "\n",
        "# Create new excel and dataframe\n",
        "new_workbook = openpyxl.Workbook()\n",
        "new_sheet = new_workbook.active\n",
        "\n",
        "# Search for rows\n",
        "for row in original_sheet.iter_rows(min_row=2, values_only=True):  # begin from the second row\n",
        "    cell_value = row[1]  # Values for B\n",
        "\n",
        "    # finding the information between <>\n",
        "    if '<' in cell_value or '>' in cell_value:\n",
        "        new_sheet.append(row)\n",
        "\n",
        "# Save new dataframe\n",
        "new_workbook.save('/content/folder/this is the file for groups.xlsx',)\n",
        "\n",
        "# Close\n",
        "original_workbook.close()\n",
        "new_workbook.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "M5cFgxLql_XV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "JJUr4pDMmtKq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3"
      ],
      "metadata": {
        "id": "ZntUK91oN676"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keep the information between <>\n"
      ],
      "metadata": {
        "id": "Ovm_5EsxmxGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This is for extracting information in groups\n",
        "import pandas as pd\n",
        "\n",
        "# Read\n",
        "file_path = '/content/folder/this is the file for groups.xlsx'  # 请替换成你的Excel文件路径\n",
        "df = pd.read_excel(file_path)\n",
        "df.columns = [\n",
        "'A'\n",
        ",\n",
        "'0'\n",
        ",\n",
        "'1'\n",
        "]\n",
        "\n",
        "# Create new dataframe\n",
        "# new_df = df[['B', 'C']]\n",
        "new_df = df[['0', '1']]\n",
        "\n",
        "# Extract Information\n",
        "def extract_content(cell_value):\n",
        "    start = cell_value.find('<')\n",
        "    end = cell_value.find('>')\n",
        "    if start != -1 and end != -1:\n",
        "        return cell_value[start + 1:end]\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "# 应用提取函数到每个单元格\n",
        "new_df['0'] = new_df['0'].apply(extract_content)\n",
        "new_df['1'] = new_df['1'].apply(extract_content)\n",
        "\n",
        "# Save\n",
        "new_file_path = '/content/folder/The elements in groups.xlsx'  # 请替换成你想保存的新文件路径\n",
        "new_df.to_excel(new_file_path, index=False)\n",
        "\n",
        "print(\"Thiis is the elements in the groups\")\n"
      ],
      "metadata": {
        "id": "5qXw_D_lrXBB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed0ca52a-940f-46ac-f262-b1f51c7f256a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thiis is the elements in the groups\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-2e9600213697>:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  new_df['0'] = new_df['0'].apply(extract_content)\n",
            "<ipython-input-8-2e9600213697>:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  new_df['1'] = new_df['1'].apply(extract_content)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4"
      ],
      "metadata": {
        "id": "K4fCnO-jOK4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This is for finding the tags in each group\n",
        "import re\n",
        "def custom_split(s):\n",
        "    result = []\n",
        "    buffer = ''\n",
        "    in_angle_bracket = False\n",
        "    in_curly_bracket = False\n",
        "\n",
        "    for c in s:\n",
        "        if c == '<':\n",
        "            in_angle_bracket = True\n",
        "        elif c == '>':\n",
        "            in_angle_bracket = False\n",
        "        elif c == '{':\n",
        "            in_curly_bracket = True\n",
        "        elif c == '}':\n",
        "            in_curly_bracket = False\n",
        "\n",
        "        buffer += c\n",
        "\n",
        "        if c == ' ' and not (in_angle_bracket or in_curly_bracket):\n",
        "            if buffer.strip():\n",
        "                result.append(buffer.strip())\n",
        "                buffer = ''\n",
        "\n",
        "    if buffer.strip():\n",
        "        result.append(buffer.strip())\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "\n",
        "def has_pattern(s):\n",
        "    pattern = r'\\d+_[^_]+_\\d+'\n",
        "    return bool(re.search(pattern, s))\n",
        "def find_pattern(s):\n",
        "    pattern = r'\\d+_[^_]+_\\d+'\n",
        "    match = re.search(pattern, s)\n",
        "    return match.group(0) if match else None\n",
        "\n",
        "def patterns_equal(s1, s2):\n",
        "    pattern1 = find_pattern(s1)\n",
        "    pattern2 = find_pattern(s2)\n",
        "    return pattern1 == pattern2\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_excel('/content/folder/The elements in groups.xlsx')\n",
        "#for i in df.index:\n",
        "result=[]\n",
        "for i in df.index:\n",
        "    s2=str(df.iloc[i,1])\n",
        "    s1=str(df.iloc[i,0])\n",
        "    s1=custom_split(s1)\n",
        "    s2=custom_split(s2)\n",
        "    tmp_s1=[]\n",
        "    tmp_s2=[]\n",
        "    for i in s1:\n",
        "        if(has_pattern(i)):\n",
        "            tmp_s1.append(i)\n",
        "    for j in s2:\n",
        "        if(has_pattern(i)):\n",
        "            tmp_s2.append(j)\n",
        "    for p in tmp_s1:\n",
        "        for q in tmp_s2:\n",
        "            if(patterns_equal(p,q)):\n",
        "                result.append([p,q])\n",
        "\n",
        "result=pd.DataFrame(result)\n",
        "result.to_excel('/content/folder/This is the tag information in groups.xlsx')"
      ],
      "metadata": {
        "id": "QCd_TUVFaOIE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5"
      ],
      "metadata": {
        "id": "Mz1z6fxhOOTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "excel1_file = '/content/1st_classification.xlsx'\n",
        "excel2_file = '/content/folder/This is the tag information in groups.xlsx'\n",
        "\n",
        "\n",
        "df1 = pd.read_excel(excel1_file)\n",
        "df2 = pd.read_excel(excel2_file)\n",
        "\n",
        "# Combine\n",
        "merged_df = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "# Merged and save\n",
        "merged_file = 'Final result.xlsx'\n",
        "merged_df.to_excel(merged_file, index=False)\n",
        "\n",
        "print(f'The merged result has been saved {merged_file}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wephD475DHuq",
        "outputId": "f4607957-d50a-4214-e558-e9b3811c1fe6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The merged result has been saved Final result.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "29diFjksslEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 读取Excel表格\n",
        "df = pd.read_excel('/content/Final result.xlsx')\n",
        "\n",
        "# 创建一个空字典来存储以'nn'为后缀的词的数量\n",
        "nn_counts = {}\n",
        "\n",
        "# 遍历Excel表格的某一列，假设列名为'Words'，根据实际情况修改列名\n",
        "for word in df[1]:\n",
        "    # 检查词是否以'nn'为后缀\n",
        "    if word.endswith('nn_1'): #change this for the things you want\n",
        "        # 如果以'nn'为后缀，将其添加到字典中或增加计数\n",
        "        nn_counts[word] = nn_counts.get(word, 0) + 1\n",
        "\n",
        "# 计算以'nn'为后缀的词的总数量\n",
        "total_nn_words = sum(nn_counts.values())\n",
        "\n",
        "# 打印每个以'nn'为后缀的词及其数量\n",
        "for word, count in nn_counts.items():\n",
        "    print(f\"{word}: {count}\")\n",
        "\n",
        "# 打印总数量\n",
        "print(f\"总共以'nn'为后缀的词的数量: {total_nn_words}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xDmjhrB0NAA",
        "outputId": "e3442242-1088-44ae-95f8-91ca9c66a7d9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "病/n_34_nn_1: 1\n",
            "食量/n_121_nn_1: 1\n",
            "定限/n_143_nn_1: 1\n",
            "牙齒/n_145_nn_1: 1\n",
            "食物/n_175_nn_1: 1\n",
            "食物/n_200_nn_1: 1\n",
            "病人/n_235_nn_1: 1\n",
            "肚腸/n_262_nn_1: 1\n",
            "蛋/n_264_nn_1: 1\n",
            "牛乳/n_266_nn_1: 1\n",
            "火雞/n_268_nn_1: 1\n",
            "牛肉/n_270_nn_1: 1\n",
            "米飯/n_275_nn_1: 1\n",
            "大麥/n_278_nn_1: 1\n",
            "番薯/n_280_nn_1: 1\n",
            "蛋白質/n_288_nn_1: 1\n",
            "食物/n_298_nn_1: 1\n",
            "燐/n_362_nn_1: 1\n",
            "燐/n_366_nn_1: 1\n",
            "膽汁/n_381_nn_1: 1\n",
            "糞/n_402_nn_1: 1\n",
            "膽汁/n_414_nn_1: 1\n",
            "腸/n_415_nn_1: 1\n",
            "肝/n_442_nn_1: 1\n",
            "食物/n_561_nn_1: 1\n",
            "血/n_577_nn_1: 1\n",
            "血/n_596_nn_1: 1\n",
            "血/n_610_nn_1: 1\n",
            "血/n_623_nn_1: 1\n",
            "血/n_638_nn_1: 1\n",
            "男子/n_708_nn_1: 1\n",
            "人身/n_726_nn_1: 1\n",
            "呆白色/n_810_nn_1: 1\n",
            "水/n_873_nn_1: 1\n",
            "肺/n_102_nnn_1: 1\n",
            "胸膛/n_178_nnn_1: 1\n",
            "輕風/n_180_nnn_1: 1\n",
            "胡琴/n_280_nnn_1: 1\n",
            "聲音/n_366_nnn_1: 1\n",
            "六畜/n_239_nn_1: 1\n",
            "物質/n_313_nn_1: 1\n",
            "水/n_768_nn_1: 1\n",
            "物/n_913_nn_1: 1\n",
            "总共以'nn'为后缀的词的数量: 43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 假设df是你的DataFrame，[1]表示你要处理的列\n",
        "# 以下是一个示例DataFrame，你需要替换成你的实际数据\n",
        "\n",
        "\n",
        "# 对[1]列中的每一行提取后四位，并统计不同后缀的数量\n",
        "suffix_count = {}\n",
        "for index, value in df[1].items():\n",
        "    suffix = str(value)[-4:]\n",
        "    if suffix not in suffix_count:\n",
        "        suffix_count[suffix] = []\n",
        "    suffix_count[suffix].append(index)\n",
        "\n",
        "# 打印出每种后缀对应的行\n",
        "for suffix, rows in suffix_count.items():\n",
        "    print(f'后缀 {suffix} 出现在行 {rows} 數量爲 {len(rows)}')\n",
        "\n",
        "print('The numern of suffix is:', len(suffix_count))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJXP_Dk21-DG",
        "outputId": "36983496-c506-4b01-f33c-6ec61323ab0d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "后缀 vv_1 出现在行 [0, 24, 29, 36, 65, 72, 75, 77, 99, 119, 164, 206, 217, 221] 數量爲 14\n",
            "后缀 ZP_2 出现在行 [1, 35, 76, 123, 175, 194] 數量爲 6\n",
            "后缀 nn_3 出现在行 [2, 17, 49, 54, 113, 169, 185, 247, 256, 260, 269] 數量爲 11\n",
            "后缀 ZP_1 出现在行 [3, 23, 30, 71, 98, 144, 174] 數量爲 7\n",
            "后缀 nn_1 出现在行 [4, 14, 15, 16, 22, 26, 32, 42, 43, 47, 50, 52, 57, 59, 60, 61, 66, 83, 84, 86, 90, 95, 97, 106, 125, 133, 139, 143, 145, 158, 176, 179, 196, 202, 225, 228, 230, 235, 239, 243, 249, 265, 271] 數量爲 43\n",
            "后缀 nv_1 出现在行 [5, 111] 數量爲 2\n",
            "后缀 nn_2 出现在行 [6, 8, 48, 51, 53, 68, 100, 112, 120, 140, 161, 183, 207, 218, 229, 244, 252, 264, 267] 數量爲 19\n",
            "后缀 aa_1 出现在行 [7, 34, 91, 150, 154, 181, 211, 245, 251, 253, 259] 數量爲 11\n",
            "后缀 cl_2 出现在行 [9, 94, 115, 121, 203, 205] 數量爲 6\n",
            "后缀 ZP_5 出现在行 [10] 數量爲 1\n",
            "后缀 WP_1 出现在行 [11, 19, 78, 85, 88, 104, 107, 109, 117, 128, 149, 170, 173, 178, 188, 190, 198, 199, 201, 204, 209] 數量爲 21\n",
            "后缀 WP_2 出现在行 [12, 20, 27, 92, 134, 142, 151, 155, 159, 212, 216] 數量爲 11\n",
            "后缀 cl_1 出现在行 [13, 79, 160, 208, 220] 數量爲 5\n",
            "后缀 aa_4 出现在行 [18, 147, 180] 數量爲 3\n",
            "后缀 ZP_3 出现在行 [21, 33, 89, 110, 114, 126, 135, 187, 191, 210] 數量爲 10\n",
            "后缀 lP_2 出现在行 [25, 105] 數量爲 2\n",
            "后缀 vP_1 出现在行 [28] 數量爲 1\n",
            "后缀 vv_3 出现在行 [31, 38, 152, 156] 數量爲 4\n",
            "后缀 nP_1 出现在行 [37, 101, 116, 118, 124] 數量爲 5\n",
            "后缀 dv_2 出现在行 [39] 數量爲 1\n",
            "后缀 ZP_4 出现在行 [40, 81, 177] 數量爲 3\n",
            "后缀 vv_2 出现在行 [41, 62, 87, 102, 129, 146, 171, 222, 224, 238, 248] 數量爲 11\n",
            "后缀 tl_2 出现在行 [44] 數量爲 1\n",
            "后缀 tl_3 出现在行 [45] 數量爲 1\n",
            "后缀 nn_4 出现在行 [46, 55, 241, 258] 數量爲 4\n",
            "后缀 nn_5 出现在行 [56] 數量爲 1\n",
            "后缀 tl_1 出现在行 [58, 63, 69, 74, 131, 163, 172, 186, 197, 215, 255] 數量爲 11\n",
            "后缀 cl_3 出现在行 [64, 162] 數量爲 2\n",
            "后缀 aa_3 出现在行 [67, 166, 234, 266] 數量爲 4\n",
            "后缀 lP_3 出现在行 [70, 136, 193] 數量爲 3\n",
            "后缀 nP_2 出现在行 [73, 93, 127] 數量爲 3\n",
            "后缀 va_1 出现在行 [80] 數量爲 1\n",
            "后缀 PW_1 出现在行 [82] 數量爲 1\n",
            "后缀 nv_2 出现在行 [96, 168, 254] 數量爲 3\n",
            "后缀 nv_3 出现在行 [103, 189, 240] 數量爲 3\n",
            "后缀 aa_2 出现在行 [108, 165, 233, 246, 270] 數量爲 5\n",
            "后缀 dd_1 出现在行 [122] 數量爲 1\n",
            "后缀 WP_3 出现在行 [130, 141, 182] 數量爲 3\n",
            "后缀 nP_4 出现在行 [132, 200] 數量爲 2\n",
            "后缀 vv_5 出现在行 [137] 數量爲 1\n",
            "后缀 ZP_8 出现在行 [138] 數量爲 1\n",
            "后缀 nP_3 出现在行 [148, 195] 數量爲 2\n",
            "后缀 WP_4 出现在行 [153, 157, 167, 192] 數量爲 4\n",
            "后缀 av_1 出现在行 [184, 263] 數量爲 2\n",
            "后缀 vv_6 出现在行 [213] 數量爲 1\n",
            "后缀 nP_5 出现在行 [214] 數量爲 1\n",
            "后缀 lP_4 出现在行 [219] 數量爲 1\n",
            "后缀 n]_3 出现在行 [223] 數量爲 1\n",
            "后缀 Z]_2 出现在行 [226] 數量爲 1\n",
            "后缀 n]_1 出现在行 [227, 231, 236, 237] 數量爲 4\n",
            "后缀 vv_4 出现在行 [232] 數量爲 1\n",
            "后缀 av_4 出现在行 [242] 數量爲 1\n",
            "后缀 an_3 出现在行 [250] 數量爲 1\n",
            "后缀 an_1 出现在行 [257] 數量爲 1\n",
            "后缀 av_6 出现在行 [261] 數量爲 1\n",
            "后缀 aa_7 出现在行 [262] 數量爲 1\n",
            "后缀 av_2 出现在行 [268] 數量爲 1\n",
            "The numern of suffix is: 57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PKD8zGDf3SYF"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}